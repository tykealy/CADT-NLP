{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKmNazkTYGPw"
   },
   "source": [
    "**Segment a string into sentences using NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Di8560uSYPcW"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "text = \"John loves apples. He eats it everyday. However, he likes oragne more.\"\n",
    "\n",
    "# text must be a string\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMcI_464Y5UG"
   },
   "source": [
    "**Segment a string into tokens using NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "548wCe64Y7a4"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = \"John loves apples\"\n",
    "\n",
    "# text must be a string\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnOXOhG9ZkWu"
   },
   "source": [
    "**Storing all words which end in \"ed\" into a list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pUtIPZ-Y9Yx",
    "outputId": "cfa5505b-802d-45e0-cad8-d3a4b88e8126"
   },
   "outputs": [],
   "source": [
    "# create an empty list in which you will store the words ending in -ed:\n",
    "ed_words = []\n",
    "\n",
    "tokens = [\"displayed\", \"ted\",\"apple\"]\n",
    "# Iterate over the list of tokens\n",
    "for token in tokens:\n",
    "    # check if a token ends with -ed\n",
    "    if token.endswith(\"ed\"):\n",
    "        # if the condition is met, add it to the ed-list\n",
    "        ed_words.append(token)\n",
    "\n",
    "print(ed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2zsqivaZ7Gv"
   },
   "source": [
    "**Removing punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# Get the list of punctuation characters\n",
    "punctuation_list = list(string.punctuation)\n",
    "\n",
    "# Print the list of punctuation\n",
    "print(punctuation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRnEXovyZ9N3"
   },
   "outputs": [],
   "source": [
    "# Define a translation table that maps each punctuation sign to the empty string\n",
    "# i.e., that deletes punctuation signs\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "\n",
    "text = 'string with \"punctuation\" inside of it! Does this work? I hope so.'\n",
    "\n",
    "# Apply the translation table to a string\n",
    "# This deletes all punctuation signs in that string\n",
    "no_punc = text.translate(translator)\n",
    "print(no_punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HuC_YEiaXoH"
   },
   "source": [
    "**Lowercasing a token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALkvP_C1aR_J"
   },
   "outputs": [],
   "source": [
    "token = \"Amelie\"\n",
    "print(token.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbO9JHe5aj92"
   },
   "source": [
    "**Retrieving NLTK Stop Words list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFqOMHNlalxN"
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "en_stopwords = stopwords.words('english')\n",
    "print(en_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaOGf-Qga36-"
   },
   "source": [
    "**Lemmatizing with NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_wkWGTBapfT"
   },
   "outputs": [],
   "source": [
    "# Instantiate a lemmatizer object\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "#nltk.download('wordnet')\n",
    "word_form = \"suppressed\"\n",
    "\n",
    "# For this lemmatizer, we need to indicate the POS of the word\n",
    "# (in this case, v for verb)\n",
    "lemma = lemmatizer.lemmatize(word_form, \"v\")\n",
    "print(word_form, lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming with NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Instantiate a stemmer object\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "word_form = \"beautifully\"\n",
    "\n",
    "# Perform stemming\n",
    "stemmed_word = stemmer.stem(word_form)\n",
    "\n",
    "print(word_form, stemmed_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oArSFuU4mG7j"
   },
   "source": [
    "**POS Tagging with NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ff76rgh0a87F"
   },
   "outputs": [],
   "source": [
    "sentence = \"Amélie is a story about a girl named Amélie whose childhood was suppressed by her Father's mistaken concerns of a heart defect.\"\n",
    "\n",
    "# Tokenize and Pos-tag the sentence\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "tagged_tokens"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}